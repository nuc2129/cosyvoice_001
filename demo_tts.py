#!/usr/bin/env python3
"""
CosyVoice å®Œæ•´åŠŸèƒ½æ¼”ç¤º
æ”¯æŒå¤šç¨®èªéŸ³åˆæˆæ¨¡å¼
"""

import sys
sys.path.append('third_party/Matcha-TTS')

from pathlib import Path
import torchaudio
from typing import Optional


class CosyVoiceDemo:
    """CosyVoice æ¼”ç¤ºé¡"""
    
    def __init__(self, model_path: str):
        """åˆå§‹åŒ–æ¨¡å‹"""
        self.model_path = model_path
        self.output_dir = Path('output')
        self.output_dir.mkdir(exist_ok=True)
        self.cosyvoice = None
        self.sample_rate = None
    
    def load_model(self) -> bool:
        """è¼‰å…¥æ¨¡å‹"""
        try:
            from cosyvoice.cli.cosyvoice import CosyVoice2
            print(f"ğŸ“¥ è¼‰å…¥æ¨¡å‹: {self.model_path}...")
            self.cosyvoice = CosyVoice2(
                self.model_path,
                load_jit=False,
                load_trt=False,
                fp16=False
            )
            self.sample_rate = self.cosyvoice.sample_rate
            print(f"âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ! (æ¡æ¨£ç‡: {self.sample_rate}Hz)")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            return False
    
    def synthesize(self, text: str, mode: str = 'basic', **kwargs) -> Optional[str]:
        """
        åˆæˆèªéŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            mode: åˆæˆæ¨¡å¼ ('basic', 'zero_shot', 'instruct')
            **kwargs: å…¶ä»–åƒæ•¸
        
        Returns:
            è¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        """
        if not self.cosyvoice:
            print("âŒ æ¨¡å‹æœªè¼‰å…¥")
            return None
        
        try:
            print(f"\nğŸ“ æ–‡æœ¬: {text}")
            print(f"ğŸµ æ¨¡å¼: {mode}")
            print("â³ æ­£åœ¨åˆæˆ...")
            
            if mode == 'zero_shot':
                # é›¶æ ·æœ¬åˆæˆéœ€è¦æç¤ºéŸ³é »
                prompt_file = kwargs.get('prompt_file', './asset/zero_shot_prompt.wav')
                voice_prompt = kwargs.get('voice_prompt', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚')
                
                if not Path(prompt_file).exists():
                    print(f"âš ï¸  æç¤ºæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                    return None
                
                from cosyvoice.utils.file_utils import load_wav
                prompt_speech = load_wav(prompt_file, 16000)
                
                results = list(self.cosyvoice.inference_zero_shot(
                    text,
                    voice_prompt,
                    prompt_speech,
                    stream=False
                ))
            
            elif mode == 'instruct':
                # æŒ‡ä»¤å¼åˆæˆ
                instruction = kwargs.get('instruction', 'ç”¨æ¨™æº–æ™®é€šè©±èªªé€™å¥è©±')
                prompt_file = kwargs.get('prompt_file', './asset/zero_shot_prompt.wav')
                
                if not Path(prompt_file).exists():
                    print(f"âš ï¸  æç¤ºæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
                    return None
                
                from cosyvoice.utils.file_utils import load_wav
                prompt_speech = load_wav(prompt_file, 16000)
                
                results = list(self.cosyvoice.inference_instruct2(
                    text,
                    instruction,
                    prompt_speech,
                    stream=False
                ))
            
            else:  # basic mode
                # åŸºç¤åˆæˆ
                results = list(self.cosyvoice.inference_zero_shot(
                    text,
                    '',
                    '',
                    stream=False
                ))
            
            # ä¿å­˜çµæœ
            output_files = []
            for i, result in enumerate(results):
                output_file = self.output_dir / f'{mode}_{len(list(self.output_dir.glob("*")))}_{i}.wav'
                torchaudio.save(str(output_file), result['tts_speech'], self.sample_rate)
                output_files.append(str(output_file))
                print(f"âœ“ å·²ä¿å­˜: {output_file}")
            
            return output_files[0] if output_files else None
            
        except Exception as e:
            print(f"âŒ åˆæˆå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None


def main():
    """ä¸»ç¨‹åº"""
    print("\n" + "="*60)
    print("ğŸ¤ CosyVoice èªéŸ³åˆæˆæ¼”ç¤º")
    print("="*60)
    
    model_path = 'pretrained_models/CosyVoice2-0.5B'
    
    # æª¢æŸ¥æ¨¡å‹
    if not Path(model_path).exists():
        print(f"\nâŒ æ¨¡å‹æœªæ‰¾åˆ°: {model_path}")
        print("\nè«‹å…ˆä¸‹è¼‰æ¨¡å‹:")
        print(f'python -c "from modelscope import snapshot_download; snapshot_download(\'iic/CosyVoice2-0.5B\', local_dir=\'{model_path}\')"')
        return
    
    # åˆå§‹åŒ–æ¼”ç¤º
    demo = CosyVoiceDemo(model_path)
    
    if not demo.load_model():
        return
    
    # åŸ·è¡Œç¤ºä¾‹
    print("\n" + "-"*60)
    print("ğŸ“‹ æ¸¬è©¦ç”¨ä¾‹")
    print("-"*60)
    
    # ç¤ºä¾‹ 1: åŸºç¤ä¸­æ–‡åˆæˆ
    print("\nã€ç¤ºä¾‹ 1ã€‘åŸºç¤ä¸­æ–‡åˆæˆ")
    demo.synthesize(
        "ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨ CosyVoice èªéŸ³åˆæˆç³»çµ±ã€‚",
        mode='basic'
    )
    
    # ç¤ºä¾‹ 2: è‹±æ–‡åˆæˆ
    print("\nã€ç¤ºä¾‹ 2ã€‘è‹±æ–‡åˆæˆ")
    demo.synthesize(
        "Hello, this is a text-to-speech synthesis demonstration.",
        mode='basic'
    )
    
    # ç¤ºä¾‹ 3: å¸¶æƒ…æ„Ÿçš„åˆæˆ
    print("\nã€ç¤ºä¾‹ 3ã€‘å¸¶æƒ…æ„Ÿçš„åˆæˆ")
    demo.synthesize(
        "æˆ‘ç‰¹åˆ¥å–œæ­¡é€™å€‹ç”¢å“ï¼Œå®ƒçœŸçš„å¾ˆæ£’ï¼",
        mode='basic'
    )
    
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰æ¸¬è©¦å®Œæˆ!")
    print(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶ä½ç½®: {demo.output_dir.absolute()}")
    print("="*60)


if __name__ == "__main__":
    main()
